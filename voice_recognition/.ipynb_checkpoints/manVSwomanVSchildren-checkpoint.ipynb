{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "heated-cabin",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as pl\n",
    "import os\n",
    "import scipy.io.wavfile as wav\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "PATH = './vowels/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "commercial-symphony",
   "metadata": {},
   "outputs": [],
   "source": [
    "import enum\n",
    "\n",
    "\n",
    "def getGenderCount():\n",
    "    counterM = 0\n",
    "    counterF = 0\n",
    "    counterK = 0\n",
    "    \n",
    "    pathlist = Path(PATH).glob('*.wav')\n",
    "    for path in pathlist:\n",
    "        if(path.stem[2] == 'f'):\n",
    "            counterF += 1\n",
    "        elif(path.stem[2] == 'm'):\n",
    "            counterM += 1\n",
    "        else:\n",
    "            counterK += 1\n",
    "    return counterM, counterF, counterK\n",
    "\n",
    "def getGenderFromFilename(filename):\n",
    "    if(filename[2] == 'f'):\n",
    "        return [1, 0, 0] # female\n",
    "    elif(filename[2] == 'm'):\n",
    "        return [0, 1, 0] # male\n",
    "    else:\n",
    "        return [0, 0, 1] # kid\n",
    "    \n",
    "def getVoiceTypeFromFilename(filename):\n",
    "    if(filename[0] == 's'):\n",
    "        return 0 # syntetic voice\n",
    "    else:\n",
    "        return 1 # real voice\n",
    "    \n",
    "def isAdult(filename):\n",
    "    return filename[1] != 'k'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "cutting-juvenile",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from python_speech_features import mfcc\n",
    "\n",
    "mfccRawDatas = []\n",
    "#Read all the wav files\n",
    "pathlist = Path(PATH).glob('*.wav')\n",
    "for path in pathlist:\n",
    "    sample_rate, X = wav.read(str(path))\n",
    "    category = getGenderFromFilename(path.stem)\n",
    "    voiceType = getVoiceTypeFromFilename(path.stem)\n",
    "    #Append the data as a tuple of : (category (male, female or kid), voicetype (natural or synthetic),Mfcc data)\n",
    "    mfccRawDatas.append((category, voiceType, mfcc(X, samplerate = sample_rate, nfft = 1024)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "corporate-wrong",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "def mfccDatas(mfccRawDatas):\n",
    "    mfccDatas = []\n",
    "\n",
    "    random.shuffle(mfccRawDatas)\n",
    "\n",
    "    #Recuce the MFCCs datas with a mean of all values\n",
    "    for i in range(len(mfccRawDatas)) :\n",
    "        #Take the means of all windows\n",
    "        values = mfccRawDatas[i][2].mean(axis=0)\n",
    "        #Add the gender\n",
    "        #We know that we have to much data of kid, so we stop when we have 72 kids data\n",
    "        gender = mfccRawDatas[i][0]\n",
    "        values = np.append(values, gender)\n",
    "        #Put the row in the array\n",
    "        mfccDatas.append(values)\n",
    "\n",
    "    return np.asarray(mfccDatas)\n",
    "\n",
    "def mfccDatasOverSampling(mfccRawDatas):\n",
    "    \n",
    "    #Compute the amount of additional data we need\n",
    "    counterM, counterF, counterK = getGenderCount()\n",
    "    maxCounter = max(counterM, counterF, counterK)\n",
    "    additionalDataF = maxCounter - counterF\n",
    "    additionalDataM = maxCounter - counterM\n",
    "    additionalDataK = maxCounter - counterK\n",
    "    \n",
    "    mfccDatas = []\n",
    "    random.shuffle(mfccRawDatas)\n",
    "    #Recuce the MFCCs datas with a mean of all values\n",
    "    #while(additionalDataF > 0 && additionalDataM > 0 && additionalDataK > 0):\n",
    "    for i in range(len(mfccRawDatas)) :\n",
    "        #Take the means of all windows\n",
    "        values = mfccRawDatas[i][2].mean(axis=0)\n",
    "        #Add the gender\n",
    "        #We know that we have to much data of kid, so we stop when we have 72 kids data\n",
    "        gender = mfccRawDatas[i][0]\n",
    "        values = np.append(values, gender)\n",
    "        #Put the row in the array\n",
    "        mfccDatas.append(values)\n",
    "\n",
    "    while(additionalDataF > 0 or additionalDataM > 0 or additionalDataK > 0):\n",
    "        for i in range(len(mfccRawDatas)) :\n",
    "            values = mfccRawDatas[i][2].mean(axis=0)\n",
    "            #Add the gender\n",
    "            #We know that we have to much data of kid, so we stop when we have 72 kids data\n",
    "            gender = mfccRawDatas[i][0]\n",
    "            values = np.append(values, gender)\n",
    "            \n",
    "            if(gender[0] == 1 and additionalDataF > 0):\n",
    "                mfccDatas.append(values) # double the data\n",
    "                additionalDataF -= 1\n",
    "            if(gender[1] == 1 and additionalDataM > 0):\n",
    "                mfccDatas.append(values) # double the data\n",
    "                additionalDataM -= 1\n",
    "            if(gender[2] == 1 and additionalDataK > 0):\n",
    "                mfccDatas.append(values) # double the data\n",
    "                additionalDataK -= 1\n",
    "        \n",
    "    return np.asarray(mfccDatas)\n",
    "    \n",
    "def mfccDatasUnderSampling(mfccRawDatas):\n",
    "     #Compute the amount of additional data we need\n",
    "    counterM, counterF, counterK = getGenderCount()\n",
    "    minCounter = min(counterM, counterF, counterK)\n",
    "    nbF = 0\n",
    "    nbM = 0\n",
    "    nbK = 0\n",
    "    \n",
    "    mfccDatas = []\n",
    "    random.shuffle(mfccRawDatas)\n",
    "    #Recuce the MFCCs datas with a mean of all values\n",
    "    #while(additionalDataF > 0 && additionalDataM > 0 && additionalDataK > 0):\n",
    "    for i in range(len(mfccRawDatas)) :\n",
    "        #Take the means of all windows\n",
    "        values = mfccRawDatas[i][2].mean(axis=0)\n",
    "        #Add the gender\n",
    "        #We know that we have to much data of kid, so we stop when we have 72 kids data\n",
    "        gender = mfccRawDatas[i][0]\n",
    "        values = np.append(values, gender)\n",
    "        if(gender[0] == 1 and nbF < minCounter):\n",
    "            mfccDatas.append(values) # double the data\n",
    "            nbF += 1\n",
    "        if(gender[1] == 1 and nbM < minCounter):\n",
    "            mfccDatas.append(values) # double the data\n",
    "            nbM += 1\n",
    "        if(gender[2] == 1 and nbK < minCounter):\n",
    "            mfccDatas.append(values) # double the data\n",
    "            nbK += 1\n",
    "        \n",
    "    return np.asarray(mfccDatas)\n",
    "\n",
    "\n",
    "overSamplingDatas = mfccDatasOverSampling(mfccRawDatas)\n",
    "underSamplingDatas = mfccDatasUnderSampling(mfccRawDatas)\n",
    "datas = mfccDatas(mfccRawDatas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "conservative-constraint",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 21.90338687  -8.88053649   0.83702144  10.07505979 -23.89380195\n",
      " -35.85249852 -19.32257479  -3.83643192   4.72586426  -1.1128845\n",
      " -18.80962313  16.93730234 -22.02681128   0.           0.\n",
      "   1.        ]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "enhanced-gentleman",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "tight-remains",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(216, 16)\n",
      "(648, 16)\n",
      "(360, 16)\n"
     ]
    }
   ],
   "source": [
    "print(underSamplingDatas.shape)\n",
    "print(overSamplingDatas.shape)\n",
    "print(datas.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "configured-germany",
   "metadata": {},
   "source": [
    "# Training part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "secret-general",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlp_backprop_momentum as mlp\n",
    "import k_fold_cross_validation as cv\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rapid-roller",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 300\n",
    "LEARNING_RATE = 0.001\n",
    "MOMENTUM = 0.85\n",
    "\n",
    "K = 5\n",
    "N_TESTS = 5\n",
    "N_NEURONS = [3, 5, 7]\n",
    "#N_NEURONS = [3, 5, 7]\n",
    "\n",
    "MSE_train = np.zeros((len(N_NEURONS), EPOCHS, N_TESTS))\n",
    "MSE_test = np.zeros((len(N_NEURONS), EPOCHS, N_TESTS))\n",
    "\n",
    "for i_h, h in enumerate(N_NEURONS):                                     # looping the number of hidden neurons\n",
    "    print('Testing', h, 'neurons...')\n",
    "    nn = mlp.MLP([13, h,3, 3], 'tanh')\n",
    "        \n",
    "    for i in np.arange(N_TESTS):                                        # looping the tests\n",
    "        nn.init_weights()                                               # the network has to be reinitialized before each test\n",
    "        temp1, temp2 = cv.k_fold_cross_validation_per_epoch(nn,         # notice that we do not use cv.k_fold_cross_validation\n",
    "                                                            datas,      # but cv.k_fold_cross_validation_per_epoch which\n",
    "                                                            k=K,        # returns a value of error per each epoch\n",
    "                                                            learning_rate=LEARNING_RATE,\n",
    "                                                            momentum=MOMENTUM,\n",
    "                                                            epochs=EPOCHS)\n",
    "        # temp1 and temp2 are the training and test error. One value per epoch\n",
    "        MSE_train[i_h, :, i] = temp1\n",
    "        MSE_test[i_h, :, i] = temp2 \n",
    "\n",
    "print(\"Done !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appointed-message",
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE_train_mean = np.mean(MSE_train, axis=2)\n",
    "MSE_test_mean = np.mean(MSE_test, axis=2)\n",
    "MSE_train_sd = np.std(MSE_train, axis=2)\n",
    "MSE_test_sd = np.std(MSE_test, axis=2)\n",
    "\n",
    "v_min = min(np.min(MSE_train_mean), np.min(MSE_test_mean))\n",
    "v_max = max(np.max(MSE_train_mean), np.max(MSE_test_mean))\n",
    "\n",
    "n_rows = int(np.ceil(len(N_NEURONS)/3.0))\n",
    "pl.figure(figsize=(12,3*n_rows))\n",
    "for i_n, n in enumerate(N_NEURONS):\n",
    "    pl.subplot(n_rows, min(3, len(N_NEURONS)), i_n+1)\n",
    "    pl.fill_between(np.arange(EPOCHS), MSE_train_mean[i_n,:], MSE_train_mean[i_n,:]+MSE_train_sd[i_n,:], facecolor='blue', alpha=0.5, label='Train')\n",
    "    pl.fill_between(np.arange(EPOCHS), MSE_train_mean[i_n,:], MSE_train_mean[i_n,:]-MSE_train_sd[i_n,:], facecolor='blue', alpha=0.5)\n",
    "    pl.fill_between(np.arange(EPOCHS), MSE_test_mean[i_n,:], MSE_test_mean[i_n,:]+MSE_test_sd[i_n,:], facecolor='red', alpha=0.5, label='Test')\n",
    "    pl.fill_between(np.arange(EPOCHS), MSE_test_mean[i_n,:], MSE_test_mean[i_n,:]-MSE_test_sd[i_n,:], facecolor='red', alpha=0.5)\n",
    "    pl.ylim(v_min,0.8*v_max)\n",
    "    pl.ylabel('MSE')\n",
    "    pl.xlabel('Number of epochs')\n",
    "    pl.title(str(K)+'-fold CV with '+str(n)+' hidden neurons')\n",
    "    pl.legend()\n",
    "    pl.grid()\n",
    "pl.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "portuguese-layout",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.figure(figsize=(15,8))\n",
    "pl.subplot(2,1,1)\n",
    "pl.imshow(MSE_train_mean, vmin=np.min(MSE_train_mean), vmax=np.percentile(MSE_train_mean, 90), aspect=3, interpolation='nearest')\n",
    "pl.yticks(np.arange(len(N_NEURONS)), N_NEURONS)\n",
    "pl.xlabel('Epochs')\n",
    "pl.ylabel('Number of hidden Neurons')\n",
    "pl.title('Training')\n",
    "pl.colorbar()\n",
    "pl.subplot(2,1,2)\n",
    "pl.imshow(MSE_test_mean, vmin=np.min(MSE_test_mean), vmax=np.percentile(MSE_test_mean, 90), aspect=3, interpolation='nearest')\n",
    "pl.yticks(np.arange(len(N_NEURONS)), N_NEURONS)\n",
    "pl.xlabel('Epochs')\n",
    "pl.ylabel('Number of hidden Neurons')\n",
    "pl.title('Test')\n",
    "pl.colorbar()\n",
    "pl.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "restricted-shelter",
   "metadata": {},
   "source": [
    "# The final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "cognitive-check",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(648, 16)\n",
      "(216, 16)\n",
      "(360, 16)\n"
     ]
    }
   ],
   "source": [
    "datasets = {'Over sampling data' : overSamplingDatas, \n",
    "            'Under sampling data2' : underSamplingDatas, \n",
    "            'Natural datas' : datas}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "large-declaration",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################\n",
      "Over sampling data\n",
      "################\n",
      "MSE training:  0.043883148373848456\n",
      "MSE test:  0.06748296266030415\n",
      "Confusion matrix:\n",
      "[[187.   0.  40.]\n",
      " [  0. 213.   3.]\n",
      " [ 54.   2. 175.]]\n",
      "Classes: woman - man - kid\n",
      "Precision:  [0.77593361 0.99069767 0.80275229]\n",
      "Recall:  [0.82378855 0.98611111 0.75757576]\n",
      "F-score:  [0.7991453  0.98839907 0.77951002]\n",
      "################\n",
      "Under sampling data2\n",
      "################\n",
      "MSE training:  0.048010633610088636\n",
      "MSE test:  0.09824812961049248\n",
      "Confusion matrix:\n",
      "[[60.  1. 16.]\n",
      " [ 4. 69.  3.]\n",
      " [24.  2. 55.]]\n",
      "Classes: woman - man - kid\n",
      "Precision:  [0.68181818 0.95833333 0.74324324]\n",
      "Recall:  [0.77922078 0.90789474 0.67901235]\n",
      "F-score:  [0.72727273 0.93243243 0.70967742]\n",
      "################\n",
      "Natural datas\n",
      "################\n",
      "MSE training:  0.05100534787344356\n",
      "MSE test:  0.09173539176376391\n",
      "Confusion matrix:\n",
      "[[ 35.   1.  38.]\n",
      " [  2.  69.   4.]\n",
      " [ 26.   3. 189.]]\n",
      "Classes: woman - man - kid\n",
      "Precision:  [0.55555556 0.94520548 0.81818182]\n",
      "Recall:  [0.47297297 0.92       0.86697248]\n",
      "F-score:  [0.51094891 0.93243243 0.84187082]\n"
     ]
    }
   ],
   "source": [
    "for (key, datas) in datasets.items():\n",
    "    nn = mlp.MLP([13,5,3,3], 'tanh')\n",
    "\n",
    "    LEARNING_RATE = 0.001\n",
    "    MOMENTUM = 0.85\n",
    "    THRESHOLD = 0.5\n",
    "    EPOCHS = 80\n",
    "    K = 5\n",
    "\n",
    "    MSE_train, MSE_test, conf_mat, target_test, output_test = cv.k_fold_cross_validation(nn,\n",
    "                                                              datas,\n",
    "                                                              k=K,\n",
    "                                                              learning_rate=LEARNING_RATE,\n",
    "                                                              momentum=MOMENTUM,\n",
    "                                                              epochs=EPOCHS,\n",
    "                                                              threshold=THRESHOLD)\n",
    "    \n",
    "    \n",
    "    print('################')\n",
    "    print(key)\n",
    "    print('################')\n",
    "    print('MSE training: ', MSE_train)\n",
    "    print('MSE test: ', MSE_test)\n",
    "    print('Confusion matrix:')\n",
    "    print(conf_mat)\n",
    "    \n",
    "    tp = np.diag(conf_mat)\n",
    "    fp = np.sum(conf_mat, axis=0) - tp\n",
    "    fn = np.sum(conf_mat, axis=1) - tp\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    fscore = 2 * recall * precision / (recall + precision)\n",
    "\n",
    "    print(\"Classes: woman - man - kid\")\n",
    "    print(\"Precision: \", precision)\n",
    "    print(\"Recall: \", recall)\n",
    "    print(\"F-score: \", fscore)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outdoor-monte",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
