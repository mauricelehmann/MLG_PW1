{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "insured-discretion",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as pl\n",
    "import os\n",
    "import scipy.io.wavfile as wav\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "PATH = './vowels/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "boxed-cliff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import enum\n",
    "\n",
    "\n",
    "def getGenderCount():\n",
    "    counterM = 0\n",
    "    counterF = 0\n",
    "    counterK = 0\n",
    "    \n",
    "    pathlist = Path(PATH).glob('*.wav')\n",
    "    for path in pathlist:\n",
    "        if(path.stem[2] == 'f'):\n",
    "            counterF += 1\n",
    "        elif(path.stem[2] == 'm'):\n",
    "            counterM += 1\n",
    "        else:\n",
    "            counterK += 1\n",
    "    return counterM, counterF, counterK\n",
    "\n",
    "def getGenderFromFilename(filename):\n",
    "    if(filename[2] == 'f'):\n",
    "        return [1, 0, 0] # female\n",
    "    elif(filename[2] == 'm'):\n",
    "        return [0, 1, 0] # male\n",
    "    else:\n",
    "        return [0, 0, 1] # kid\n",
    "    \n",
    "def getVoiceTypeFromFilename(filename):\n",
    "    if(filename[0] == 's'):\n",
    "        return 0 # syntetic voice\n",
    "    else:\n",
    "        return 1 # real voice\n",
    "    \n",
    "def isAdult(filename):\n",
    "    return filename[1] != 'k'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "upper-burns",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from python_speech_features import mfcc\n",
    "\n",
    "mfccRawDatas = []\n",
    "#Read all the wav files\n",
    "pathlist = Path(PATH).glob('*.wav')\n",
    "for path in pathlist:\n",
    "    sample_rate, X = wav.read(str(path))\n",
    "    category = getGenderFromFilename(path.stem)\n",
    "    voiceType = getVoiceTypeFromFilename(path.stem)\n",
    "    #Append the data as a tuple of : (category (male, female or kid), voicetype (natural or synthetic),Mfcc data)\n",
    "    mfccRawDatas.append((category, voiceType, mfcc(X, samplerate = sample_rate, nfft = 1024)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "voluntary-brand",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "def mfccDatas(mfccRawDatas):\n",
    "    mfccDatas = []\n",
    "\n",
    "    random.shuffle(mfccRawDatas)\n",
    "\n",
    "    #Recuce the MFCCs datas with a mean of all values\n",
    "    for i in range(len(mfccRawDatas)) :\n",
    "        #Take the means of all windows\n",
    "        values = mfccRawDatas[i][2].mean(axis=0)\n",
    "        #Add the gender\n",
    "        #We know that we have to much data of kid, so we stop when we have 72 kids data\n",
    "        gender = mfccRawDatas[i][0]\n",
    "        values = np.append(values, gender)\n",
    "        #Put the row in the array\n",
    "        mfccDatas.append(values)\n",
    "\n",
    "    return np.asarray(mfccDatas)\n",
    "\n",
    "def mfccDatasOverSampling(mfccRawDatas):\n",
    "    \n",
    "    #Compute the amount of additional data we need\n",
    "    counterM, counterF, counterK = getGenderCount()\n",
    "    maxCounter = max(counterM, counterF, counterK)\n",
    "    additionalDataF = maxCounter - counterF\n",
    "    additionalDataM = maxCounter - counterM\n",
    "    additionalDataK = maxCounter - counterK\n",
    "    \n",
    "    mfccDatas = []\n",
    "    random.shuffle(mfccRawDatas)\n",
    "    #Recuce the MFCCs datas with a mean of all values\n",
    "    #while(additionalDataF > 0 && additionalDataM > 0 && additionalDataK > 0):\n",
    "    for i in range(len(mfccRawDatas)) :\n",
    "        #Take the means of all windows\n",
    "        values = mfccRawDatas[i][2].mean(axis=0)\n",
    "        #Add the gender\n",
    "        #We know that we have to much data of kid, so we stop when we have 72 kids data\n",
    "        gender = mfccRawDatas[i][0]\n",
    "        values = np.append(values, gender)\n",
    "        #Put the row in the array\n",
    "        mfccDatas.append(values)\n",
    "\n",
    "    while(additionalDataF > 0 or additionalDataM > 0 or additionalDataK > 0):\n",
    "        for i in range(len(mfccRawDatas)) :\n",
    "            values = mfccRawDatas[i][2].mean(axis=0)\n",
    "            #Add the gender\n",
    "            #We know that we have to much data of kid, so we stop when we have 72 kids data\n",
    "            gender = mfccRawDatas[i][0]\n",
    "            values = np.append(values, gender)\n",
    "            \n",
    "            if(gender[0] == 1 and additionalDataF > 0):\n",
    "                mfccDatas.append(values) # double the data\n",
    "                additionalDataF -= 1\n",
    "            if(gender[1] == 1 and additionalDataM > 0):\n",
    "                mfccDatas.append(values) # double the data\n",
    "                additionalDataM -= 1\n",
    "            if(gender[2] == 1 and additionalDataK > 0):\n",
    "                mfccDatas.append(values) # double the data\n",
    "                additionalDataK -= 1\n",
    "        \n",
    "    return np.asarray(mfccDatas)\n",
    "    \n",
    "def mfccDatasUnderSampling(mfccRawDatas):\n",
    "     #Compute the amount of additional data we need\n",
    "    counterM, counterF, counterK = getGenderCount()\n",
    "    minCounter = min(counterM, counterF, counterK)\n",
    "    nbF = 0\n",
    "    nbM = 0\n",
    "    nbK = 0\n",
    "    \n",
    "    mfccDatas = []\n",
    "    random.shuffle(mfccRawDatas)\n",
    "    #Recuce the MFCCs datas with a mean of all values\n",
    "    #while(additionalDataF > 0 && additionalDataM > 0 && additionalDataK > 0):\n",
    "    for i in range(len(mfccRawDatas)) :\n",
    "        #Take the means of all windows\n",
    "        values = mfccRawDatas[i][2].mean(axis=0)\n",
    "        #Add the gender\n",
    "        #We know that we have to much data of kid, so we stop when we have 72 kids data\n",
    "        gender = mfccRawDatas[i][0]\n",
    "        values = np.append(values, gender)\n",
    "        if(gender[0] == 1 and nbF < minCounter):\n",
    "            mfccDatas.append(values) # double the data\n",
    "            nbF += 1\n",
    "        if(gender[1] == 1 and nbM < minCounter):\n",
    "            mfccDatas.append(values) # double the data\n",
    "            nbM += 1\n",
    "        if(gender[2] == 1 and nbK < minCounter):\n",
    "            mfccDatas.append(values) # double the data\n",
    "            nbK += 1\n",
    "        \n",
    "    return np.asarray(mfccDatas)\n",
    "\n",
    "\n",
    "overSamplingDatas = mfccDatasOverSampling(mfccRawDatas)\n",
    "underSamplingDatas = mfccDatasUnderSampling(mfccRawDatas)\n",
    "datas = mfccDatas(mfccRawDatas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "educational-passion",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exposed-campaign",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "surprising-attempt",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(216, 16)\n",
      "(648, 16)\n",
      "(360, 16)\n"
     ]
    }
   ],
   "source": [
    "print(underSamplingDatas.shape)\n",
    "print(overSamplingDatas.shape)\n",
    "print(datas.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clinical-daisy",
   "metadata": {},
   "source": [
    "# Training part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "pleased-australia",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlp_backprop_momentum as mlp\n",
    "import k_fold_cross_validation as cv\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brilliant-barbados",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing 3 neurons...\n",
      "Testing 5 neurons...\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 300\n",
    "LEARNING_RATE = 0.001\n",
    "MOMENTUM = 0.85\n",
    "\n",
    "K = 5\n",
    "N_TESTS = 5\n",
    "N_NEURONS = [3, 5, 7]\n",
    "\n",
    "MSE_train = np.zeros((len(N_NEURONS), EPOCHS, N_TESTS))\n",
    "MSE_test = np.zeros((len(N_NEURONS), EPOCHS, N_TESTS))\n",
    "\n",
    "for i_h, h in enumerate(N_NEURONS):                                     # looping the number of hidden neurons\n",
    "    print('Testing', h, 'neurons...')\n",
    "    nn = mlp.MLP([13, h,3, 3], 'tanh')\n",
    "        \n",
    "    for i in np.arange(N_TESTS):                                        # looping the tests\n",
    "        nn.init_weights()                                               # the network has to be reinitialized before each test\n",
    "        temp1, temp2 = cv.k_fold_cross_validation_per_epoch(nn,         # notice that we do not use cv.k_fold_cross_validation\n",
    "                                                            datas,      # but cv.k_fold_cross_validation_per_epoch which\n",
    "                                                            k=K,        # returns a value of error per each epoch\n",
    "                                                            learning_rate=LEARNING_RATE,\n",
    "                                                            momentum=MOMENTUM,\n",
    "                                                            epochs=EPOCHS)\n",
    "        # temp1 and temp2 are the training and test error. One value per epoch\n",
    "        MSE_train[i_h, :, i] = temp1\n",
    "        MSE_test[i_h, :, i] = temp2 \n",
    "\n",
    "print(\"Done !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prerequisite-minister",
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE_train_mean = np.mean(MSE_train, axis=2)\n",
    "MSE_test_mean = np.mean(MSE_test, axis=2)\n",
    "MSE_train_sd = np.std(MSE_train, axis=2)\n",
    "MSE_test_sd = np.std(MSE_test, axis=2)\n",
    "\n",
    "v_min = min(np.min(MSE_train_mean), np.min(MSE_test_mean))\n",
    "v_max = max(np.max(MSE_train_mean), np.max(MSE_test_mean))\n",
    "\n",
    "n_rows = int(np.ceil(len(N_NEURONS)/3.0))\n",
    "pl.figure(figsize=(12,3*n_rows))\n",
    "for i_n, n in enumerate(N_NEURONS):\n",
    "    pl.subplot(n_rows, min(3, len(N_NEURONS)), i_n+1)\n",
    "    pl.fill_between(np.arange(EPOCHS), MSE_train_mean[i_n,:], MSE_train_mean[i_n,:]+MSE_train_sd[i_n,:], facecolor='blue', alpha=0.5, label='Train')\n",
    "    pl.fill_between(np.arange(EPOCHS), MSE_train_mean[i_n,:], MSE_train_mean[i_n,:]-MSE_train_sd[i_n,:], facecolor='blue', alpha=0.5)\n",
    "    pl.fill_between(np.arange(EPOCHS), MSE_test_mean[i_n,:], MSE_test_mean[i_n,:]+MSE_test_sd[i_n,:], facecolor='red', alpha=0.5, label='Test')\n",
    "    pl.fill_between(np.arange(EPOCHS), MSE_test_mean[i_n,:], MSE_test_mean[i_n,:]-MSE_test_sd[i_n,:], facecolor='red', alpha=0.5)\n",
    "    pl.ylim(v_min,0.8*v_max)\n",
    "    pl.ylabel('MSE')\n",
    "    pl.xlabel('Number of epochs')\n",
    "    pl.title(str(K)+'-fold CV with '+str(n)+' hidden neurons')\n",
    "    pl.legend()\n",
    "    pl.grid()\n",
    "pl.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rapid-medicare",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.figure(figsize=(15,8))\n",
    "pl.subplot(2,1,1)\n",
    "pl.imshow(MSE_train_mean, vmin=np.min(MSE_train_mean), vmax=np.percentile(MSE_train_mean, 90), aspect=3, interpolation='nearest')\n",
    "pl.yticks(np.arange(len(N_NEURONS)), N_NEURONS)\n",
    "pl.xlabel('Epochs')\n",
    "pl.ylabel('Number of hidden Neurons')\n",
    "pl.title('Training')\n",
    "pl.colorbar()\n",
    "pl.subplot(2,1,2)\n",
    "pl.imshow(MSE_test_mean, vmin=np.min(MSE_test_mean), vmax=np.percentile(MSE_test_mean, 90), aspect=3, interpolation='nearest')\n",
    "pl.yticks(np.arange(len(N_NEURONS)), N_NEURONS)\n",
    "pl.xlabel('Epochs')\n",
    "pl.ylabel('Number of hidden Neurons')\n",
    "pl.title('Test')\n",
    "pl.colorbar()\n",
    "pl.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prompt-transcription",
   "metadata": {},
   "source": [
    "# The final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cheap-turtle",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {'Over sampling data' : overSamplingDatas, \n",
    "            'Under sampling data2' : underSamplingDatas, \n",
    "            'Natural datas' : datas}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "behind-optics",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (key, datas) in datasets.items():\n",
    "    nn = mlp.MLP([13,5,3,3], 'tanh')\n",
    "\n",
    "    LEARNING_RATE = 0.001\n",
    "    MOMENTUM = 0.85\n",
    "    THRESHOLD = 0.5\n",
    "    EPOCHS = 80\n",
    "    K = 5\n",
    "\n",
    "    MSE_train, MSE_test, conf_mat, target_test, output_test = cv.k_fold_cross_validation(nn,\n",
    "                                                              datas,\n",
    "                                                              k=K,\n",
    "                                                              learning_rate=LEARNING_RATE,\n",
    "                                                              momentum=MOMENTUM,\n",
    "                                                              epochs=EPOCHS,\n",
    "                                                              threshold=THRESHOLD)\n",
    "    \n",
    "    \n",
    "    print('################')\n",
    "    print(key)\n",
    "    print('################')\n",
    "    print('MSE training: ', MSE_train)\n",
    "    print('MSE test: ', MSE_test)\n",
    "    print('Confusion matrix:')\n",
    "    print(conf_mat)\n",
    "    \n",
    "    tp = np.diag(conf_mat)\n",
    "    fp = np.sum(conf_mat, axis=0) - tp\n",
    "    fn = np.sum(conf_mat, axis=1) - tp\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    fscore = 2 * recall * precision / (recall + precision)\n",
    "\n",
    "    print(\"Classes: woman - man - kid\")\n",
    "    print(\"Precision: \", precision)\n",
    "    print(\"Recall: \", recall)\n",
    "    print(\"F-score: \", fscore)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statewide-awareness",
   "metadata": {},
   "source": [
    "## Expermiment with own voice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selected-worcester",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = mlp.MLP([13,5,3,3], 'tanh')\n",
    "\n",
    "LEARNING_RATE = 0.001\n",
    "MOMENTUM = 0.85\n",
    "THRESHOLD = 0.5\n",
    "EPOCHS = 80\n",
    "K = 5\n",
    "\n",
    "MSE_train, MSE_test, conf_mat, target_test, output_test = cv.k_fold_cross_validation(nn,\n",
    "                                                          datasets['Over sampling data'],\n",
    "                                                          k=K,\n",
    "                                                          learning_rate=LEARNING_RATE,\n",
    "                                                          momentum=MOMENTUM,\n",
    "                                                          epochs=EPOCHS,\n",
    "                                                          threshold=THRESHOLD)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "single-houston",
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile\n",
    "\n",
    "PATH  = './custom_wav/'\n",
    "#Read all the wav files\n",
    "pathlist = Path(PATH).glob('*.wav')\n",
    "for path in pathlist:\n",
    "    \n",
    "    #If wav is not well formatted with samplerated\n",
    "    #data, samplerate = soundfile.read(str(path))\n",
    "    #soundfile.write(str(path), data, samplerate, subtype='PCM_16')\n",
    "    \n",
    "    sample_rate, X = wav.read(str(path))\n",
    "    voiceType = getVoiceTypeFromFilename(path.stem)\n",
    "    mfccData = (mfcc(X, samplerate = sample_rate, nfft = 1103)).mean(axis=0)\n",
    "    \n",
    "   \n",
    "    print(str(path))\n",
    "    pred = nn.predict(mfccData)\n",
    "    print('Values : \\n', pred)\n",
    "    print('Prediected gender : ')\n",
    "\n",
    "    if(pred[0] > THRESHOLD):\n",
    "        print('Female')\n",
    "    if(pred[1] > THRESHOLD):\n",
    "        print('Male')\n",
    "    if(pred[2] > THRESHOLD):\n",
    "        print('Kid')\n",
    "    print('\\n')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "functioning-garden",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
